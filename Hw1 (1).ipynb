{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704fbdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.Pick one of the datasets from the ChatBot session(s) of the TUT demo (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values by summing nulls in each column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Display the result\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0edd739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2.(1) use code provided in your ChatBot session to print out the number of rows and columns of the dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the dimensions of the dataset\n",
    "dimensions = df.shape\n",
    "\n",
    "# Display the result\n",
    "dimensions\n",
    " \n",
    "# (2) write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset\n",
    "\n",
    "#  Observations: These are the individual pieces of data in your dataset. Each row in your table is one observation, like a character or event that you're studying.\n",
    "#  Variables: These are the details or characteristics recorded for each observation. Each column in your dataset is a variable, like the name, type, or personality of a character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d459dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3.（1） \n",
    "# df.info():\n",
    "# Provides an overview of the dataset, including:\n",
    "# The number of rows (observations) and columns (variables).\n",
    "# The column names.\n",
    "# The number of non-null (non-missing) entries in each column.\n",
    "# The data types of each column (e.g., integer, float, object).\n",
    "\n",
    "# df.describe():\n",
    "# Provides basic statistical summaries of the numerical columns in the dataset:\n",
    "# Count: The number of non-null observations.\n",
    "# Mean: The average of the data.\n",
    "# Standard deviation: A measure of the spread of the data.\n",
    "# Min/Max: The minimum and maximum values.\n",
    "# Percentiles (25%, 50%, 75%): The values at those percentiles.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Simple summary of the dataset\n",
    "df.info()  # Gives a concise summary of the DataFrame\n",
    "\n",
    "df.describe()  # Provides a summary of statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c926ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Statistical Summary:\\n',\n",
       "             row_n\n",
       " count  391.000000\n",
       " mean   239.902813\n",
       " std    140.702672\n",
       " min      2.000000\n",
       " 25%    117.500000\n",
       " 50%    240.000000\n",
       " 75%    363.500000\n",
       " max    483.000000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3.（2）\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the statistical summary for numerical columns\n",
    "summary_stats = df.describe()\n",
    "\"Statistical Summary:\\n\", summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc5e6e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\nValue Counts for 'species':\\n\",\n",
       " species\n",
       " cat          23\n",
       " rabbit       20\n",
       " frog         18\n",
       " squirrel     18\n",
       " duck         17\n",
       " dog          16\n",
       " cub          16\n",
       " pig          15\n",
       " bear         15\n",
       " mouse        15\n",
       " horse        15\n",
       " bird         13\n",
       " penguin      13\n",
       " sheep        13\n",
       " elephant     11\n",
       " wolf         11\n",
       " ostrich      10\n",
       " deer         10\n",
       " eagle         9\n",
       " gorilla       9\n",
       " chicken       9\n",
       " koala         9\n",
       " goat          8\n",
       " hamster       8\n",
       " kangaroo      8\n",
       " monkey        8\n",
       " anteater      7\n",
       " hippo         7\n",
       " tiger         7\n",
       " alligator     7\n",
       " lion          7\n",
       " bull          6\n",
       " rhino         6\n",
       " cow           4\n",
       " octopus       3\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3.（2）\n",
    "# Get value counts for a specific column (e.g., 'species')\n",
    "value_counts_species = df['species'].value_counts()\n",
    "\"\\nValue Counts for 'species':\\n\", value_counts_species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b28590",
   "metadata": {},
   "source": [
    "Q4.（1）\n",
    "`df.shape` and `df.describe()` are two tools used to examine data. `df.shape` lets you see how many rows and columns the data has, regardless of what type it is, and regardless of whether there are any missing values. It tells you the overall structure of the data.\n",
    "\n",
    "And `df.describe()` is used to look at the statistics of numeric data, such as the mean and standard deviation. It only focuses on numeric data and ignores those missing values. So if you have some numeric data missing, the `counts` in `df.describe()` may be fewer than the number of rows in `df.shape`, or fewer than the number of columns in `df.shape`. This is because `df.describe()` only analyzes numerical data, whereas `df.shape` only tells you the total amount of data, regardless of the specifics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8690501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Shape of the DataFrame:', (891, 15))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4.（2）\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "shape = df.shape\n",
    "\"Shape of the DataFrame:\", shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a75e21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Descriptive statistics for all columns:\\n',\n",
       "           survived      pclass   sex         age       sibsp       parch  \\\n",
       " count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
       " unique         NaN         NaN     2         NaN         NaN         NaN   \n",
       " top            NaN         NaN  male         NaN         NaN         NaN   \n",
       " freq           NaN         NaN   577         NaN         NaN         NaN   \n",
       " mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
       " std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
       " min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
       " 25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
       " 50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
       " 75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
       " max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
       " \n",
       "               fare embarked  class  who adult_male deck  embark_town alive  \\\n",
       " count   891.000000      889    891  891        891  203          889   891   \n",
       " unique         NaN        3      3    3          2    7            3     2   \n",
       " top            NaN        S  Third  man       True    C  Southampton    no   \n",
       " freq           NaN      644    491  537        537   59          644   549   \n",
       " mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " 25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " 50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " 75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
       " \n",
       "        alone  \n",
       " count    891  \n",
       " unique     2  \n",
       " top     True  \n",
       " freq     537  \n",
       " mean     NaN  \n",
       " std      NaN  \n",
       " min      NaN  \n",
       " 25%      NaN  \n",
       " 50%      NaN  \n",
       " 75%      NaN  \n",
       " max      NaN  )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4.(2)\n",
    "\n",
    "# Get descriptive statistics for all columns\n",
    "describe_all = df.describe(include='all')\n",
    "\"Descriptive statistics for all columns:\\n\", describe_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed615846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5    https://chatgpt.com/share/abb74469-117c-4c36-909f-8cb17cc491a6\n",
    "\n",
    "# Properties are features or data of an object that directly reflect the state of the object, e.g., df.shape. they provide basic information about the object, \n",
    "# but do not require parentheses to access them; they can simply be referenced directly. Methods, on the other hand, \n",
    "# are functions or behaviors associated with an object that perform operations or calculations on the object, \n",
    "# such as df.describe(). Parentheses are required to call a method, indicating that it is a function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434febda",
   "metadata": {},
   "source": [
    "Q6.（1）\n",
    "Mean: The sum of all values divided by the number of values, the “average” of the data.\n",
    "\n",
    "Standard Deviation (Standard Deviation, std): is a measure of the degree of dispersion of data units. The larger the standard deviation, the wider the distribution of data points; the smaller the standard deviation, the more data points are concentrated near the mean.\n",
    "\n",
    "Minimum (Min): The smallest value in the data set.\n",
    "\n",
    "25th Percentile (Q1): 25% of the values in the data set are below this value. It can also be interpreted as the “top quarter” of the data.\n",
    "\n",
    "50% Percentile (50th Percentile, Q2 or Median): The middle of the data. Half of the data points are below this value and the other half are above it.\n",
    "\n",
    "75th Percentile (Q3): 75% of the values in the data set are below this value. This can be interpreted as the “top third” of the data.\n",
    "\n",
    "Max: The largest value in the data set.\n",
    "\n",
    "（2）Why these statistics only apply to numeric variables\n",
    "\n",
    "Because these results require a series of mathematical operations to be performed to arrive at them, if they are not numerical variables then the operations lose their meaning.\n",
    "\n",
    "（3）Missing value handling\n",
    "df.describe() does not remove missing values, but ignores them and computes the remaining non-null values. Even if there are missing values in a column, df.describe() will still return a summary statistic normally, except that the count value may be less than the total number of rows in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82dc50",
   "metadata": {},
   "source": [
    "Q7 ： I think the first thing to do to solve the following problem is to figure out what each of these two codes does\n",
    "  df.dropna():It works by default to remove any rows in the database that contain missing values\n",
    "  del df['col']：It works by deleting the column you specify, regardless of whether the column contains missing values or not.\n",
    "  \n",
    "  （1）：\n",
    "  This is because the data in the columns are generally the same kind of data, for example, if a column represents age, then all the data in that column represents the value of age. When we need a large number of the same type as a sample for research, or when the missing amount of data is distributed in different columns, you can choose to delete rows to ensure the integrity of the data.\n",
    "  （2）：\n",
    "  On the flip side, data rows usually contain various pieces of data for an individual, and if the data columns represented by a particular data type do not have a significant impact on the results of the study, or if missing data are concentrated in a particular column, consider deleting the data in a particular column and retaining a larger sample of individuals with complete data.\n",
    "  （3）：\n",
    "  The reason why columns are considered to be deleted first rather than rows is precisely because of their nature. If, on the contrary, too many rows are deleted because too many are missing from one column, it will affect the completeness of the data and the sample size of the other columns. Deleting columns affects the same kind of data, whereas deleting rows tends to affect the sample size of multiple kinds of data, and deleting columns will have a relatively small impact.\n",
    "  （4）：\n",
    "  I will first look for columns that are not useful for analyzing the data or that contain a lot of missing data and prioritize their removal with del df['col']. Then I look for rows that still have missing data and remove them with df.dropna() to ensure that the data is simplified and refined with minimal loss of data samples for subsequent analysis.\n",
    "  \n",
    "  \n",
    "  https://chatgpt.com/share/7c6c4f10-789b-4c61-b8b0-356baaa909f5\n",
    "  \n",
    "  ### Summary of Accomplishments:\n",
    "\n",
    "1. **Explained Summary Statistics**: We covered the definitions of summary statistics like count, mean, standard deviation, min, max, and quartiles, and discussed why these are specific to numeric variables.\n",
    "\n",
    "2. **Use Cases for `df.dropna()` and `del df['col']`**:\n",
    "   - **`df.dropna()` Use Case**: We discussed a scenario where removing rows with any missing values is preferred, such as when needing a complete dataset without any gaps in important columns.\n",
    "   - **`del df['col']` Use Case**: We covered a scenario where deleting a specific column with many missing values is preferable, especially if that column is irrelevant to the analysis.\n",
    "\n",
    "3. **Importance of Order**: We discussed why it might be beneficial to delete irrelevant columns (`del df['col']`) before applying `df.dropna()`. This ensures you’re not losing valuable rows due to missing values in columns that are not needed for analysis.\n",
    "\n",
    "4. **Example with Dataset**:\n",
    "   - **Approach**: We outlined a process for removing missing data from a dataset, including deleting irrelevant columns and then dropping rows with missing values.\n",
    "   - **Justification**: We justified the approach by explaining how it cleans the dataset effectively while retaining important information.\n",
    "   - **Before and After Report**: We included code snippets to show how to check for missing data before and after applying the cleaning steps.\n",
    "\n",
    "Feel free to ask if you need more details on any of these points or further assistance with your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae9f246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "class                                                                      \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "class                                                                 \n",
      "First   84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "Second  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "Third   13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8 （1）\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by a specific column, e.g., 'class' (if this is col1) and describe 'age' (col3) and 'fare' (col4)\n",
    "summary = df.groupby(\"class\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cb6bd",
   "metadata": {},
   "source": [
    "Q8 （2）\n",
    "The main reason for their difference comes from the difference in the way they operate. df.describe() calculates the non-missing values of each column in the DataFrame as a whole. While df.groupby(“col1”)[“col2”].describe()is the calculation of the definition of each group in the non-missing value col1. The missing value col2 will be excluded from each group. While they both ignore missing values in the data for the calculation, using df.describe()missing values affects the total number of non-missing values in all all rows, whereas df.groupby(“col1”)[“col2”].describe(), because of the different distribution of missing values within each group, results in a potentially different count for each group. Missing values affect the count of each group independently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f111f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Q8 A： Forget to include import pandas as pd in your code\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Display the first few rows to understand the structure\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Q8 A： Forget to include import pandas as pd in your code\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by a specific column, e.g., 'class' (if this is col1) and describe 'age' (col3) and 'fare' (col4)\n",
    "summary = df.groupby(\"class\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9585c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.（3）\n",
    "# A： Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Verify column names\n",
    "print(df.columns)\n",
    "\n",
    "# Group by 'class' (ensure 'class' is a valid column name in the dataset) and describe 'age' and 'fare'\n",
    "# If 'class' is not the correct column name, replace it with the correct one (e.g., 'pclass' for passenger class)\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6906797",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display the first few rows to understand the structure\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Q8.（3） B：Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by a specific column, e.g., 'class' (if this is col1) and describe 'age' (col3) and 'fare' (col4)\n",
    "summary = df.groupby(\"class\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbd9901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.（3） \n",
    "# B：Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Verify column names\n",
    "print(df.columns)\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862b29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Group by a specific column, e.g., 'class' (if this is col1) and describe 'age' (col3) and 'fare' (col4)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mGROUPBY(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfare\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the summary statistics\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "# Q8.（3） \n",
    "# c：Try to use a dataframe before it's been assigned into the variable\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by a specific column, e.g., 'class' (if this is col1) and describe 'age' (col3) and 'fare' (col4)\n",
    "summary = DF.GROUPBY(\"class\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ff8dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.（3）\n",
    "# C：Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27cb264",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (1697824977.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv url)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# Q8.（3）\n",
    "# D：Forget one of the parentheses somewhere the code\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv url)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by a specific column, e.g., 'class' (if this is col1) and describe 'age' (col3) and 'fare' (col4)\n",
    "summary = df.groupby(\"class\")[[\"age\", \"fare\"]].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcb60b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.（3）\n",
    "# D：Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Fixed syntax error by adding parentheses\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' (commonly used column name in Titanic dataset) and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()  # Changed 'class' to 'pclass'\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e27bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_180/2732849337.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the first few rows to understand the structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Group by 'pclass' (commonly used column name in Titanic dataset) and describe 'age' and 'fare'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fare\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Changed 'class' to 'pclass'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Print the summary statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "# Q8.（3）\n",
    "# E：Mistype one of the names of the chained functions with the code\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Fixed syntax error by adding parentheses\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' (commonly used column name in Titanic dataset) and describe 'age' and 'fare'\n",
    "summary = df.group_by(\"pclass\")[[\"age\", \"fare\"]].describe()  # Changed 'class' to 'pclass'\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d7c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.（3）\n",
    "# E：Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Load the dataset\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()  # Correct method name is 'groupby'\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9a0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'Age', 'Fare'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Group by 'pclass' and describe 'age' and 'fare'\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFare\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# Correct method name is 'groupby'\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the summary statistics\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:239\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mintersection(key)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)):\n\u001b[1;32m    238\u001b[0m         bad_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(bad_keys)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(\u001b[38;5;28mlist\u001b[39m(key), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'Age', 'Fare'\""
     ]
    }
   ],
   "source": [
    "# Q8.(3)\n",
    "# F: Use a column name that's not in your data for the groupby and column selection\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Load the dataset\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"Age\", \"Fare\"]].describe()  # Correct method name is 'groupby'\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529e5013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.(3)\n",
    "# F: Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Load the dataset\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()  # Correct column names\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2150e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'age' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Group by 'pclass' and describe 'age' and 'fare'\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m summary \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[\u001b[43mage\u001b[49m, fare]]\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# Correct column names\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the summary statistics\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'age' is not defined"
     ]
    }
   ],
   "source": [
    "# Q8.(3)\n",
    "# G: Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Load the dataset\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[age, fare]].describe()  # Correct column names\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f734435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "          age                                                       fare  \\\n",
      "        count       mean        std   min   25%   50%   75%   max  count   \n",
      "pclass                                                                     \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0  216.0   \n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0  184.0   \n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0  491.0   \n",
      "\n",
      "                                                                      \n",
      "             mean        std  min       25%      50%   75%       max  \n",
      "pclass                                                                \n",
      "1       84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292  \n",
      "2       20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000  \n",
      "3       13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500  \n"
     ]
    }
   ],
   "source": [
    "# Q8.(3)\n",
    "# G: Corrected results\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Load the dataset\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()  # Column names should be in quotes\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372c9f4",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/9cfed5f6-f266-41ec-b361-6e398b543a00\n",
    "\n",
    "Certainly! Here's a summary of what we've accomplished:\n",
    "\n",
    "Corrected Code Issues:\n",
    "\n",
    "We fixed syntax errors related to method names and column names in pandas operations.\n",
    "We corrected the case sensitivity and formatting issues in your code, ensuring it works as intended.\n",
    "Loaded and Analyzed Data:\n",
    "\n",
    "We successfully loaded the Titanic dataset from the provided URL into a pandas DataFrame.\n",
    "We used the groupby method to group data by passenger class (pclass) and calculated summary statistics for the age and fare columns.\n",
    "Addressed Common Errors:\n",
    "\n",
    "We addressed common issues such as incorrect method names (group_by vs. groupby), missing parentheses in function calls, and incorrect column name references.\n",
    "Final Working Code:\n",
    "\n",
    "We provided the final corrected code snippet that groups the Titanic dataset by pclass and describes the age and fare columns.\n",
    "The final working code is:\n",
    "\n",
    "python\n",
    "复制代码\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)  # Load the dataset\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'pclass' and describe 'age' and 'fare'\n",
    "summary = df.groupby(\"pclass\")[[\"age\", \"fare\"]].describe()  # Column names should be in quotes\n",
    "\n",
    "# Print the summary statistics\n",
    "print(summary)\n",
    "Feel free to ask if you have more questions or need further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 \n",
    "# Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
